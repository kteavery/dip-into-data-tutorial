{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is regression? \n",
    "\n",
    "**Question** What kind of data do we usually use for regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review the example we saw last time. The code below reads our data points from a file and then creates a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas \n",
    "import numpy \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# read data from the synthetic data file\n",
    "data = pandas.read_csv(\"../assets/regression-synthetic.csv\") \n",
    "\n",
    "# plot data and label the x-axis and y-axis\n",
    "plt.scatter(data['apple'], data['prices'], color='green')\n",
    "plt.title(\"Apples and Prices\")\n",
    "plt.xlabel(\"Apples (lb)\")\n",
    "plt.ylabel(\"Price ($)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were using this data as an example to see if given a few data points about apple quantities and their prices, if we could learn an equation (like the linear equation of the form $y = mx + c$) from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last class, we saw how one black line that we learned was the \"best fit\" for the data. But this poses many questions.\n",
    "1. How do we know that that line is the best fit? \n",
    "2. Is it possible that there are other lines that are best for the data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will answer all of these questions and more in detail as part of this lecture. First, let us see how to decide if any given line is the \"best fit\" for the data. In order to do so, we need to see what are the other candidate lines for our analysis and how to calculate error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the linear regression line in the same plot \n",
    "x = numpy.linspace(0, 12, 1000)\n",
    "plt.scatter(data['apple'], data['prices'], color='green')\n",
    "plt.plot(x, 2*x+1, color='red')\n",
    "plt.plot(x, 1*x+2, color='blue')\n",
    "plt.plot(x, 1.5*x+3, color='purple')\n",
    "plt.title(\"Apples and Prices\")\n",
    "plt.xlabel(\"Apples (lb)\")\n",
    "plt.ylabel(\"Price ($)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Can you guess which line would be the best fitting line? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed, the best fitting line is the one that is closest to most of the points! In our case, we can see that many points even go through the line itself, which this is not necessarily true. But this brings us closer to describing a measure that allows us to determine what the best line is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which line is the best-fitting line, we employ a measure called residual error. Residual error is simply the square root of the average distance between all data points and their corresponding points on the predicting line!  \n",
    "\n",
    "Let us calculate the error for the blue line in the above plot using the snippet of code in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fitting line errors \n",
    "x = numpy.linspace(0, 12, 1000)\n",
    "plt.scatter(data['apple'], data['prices'], color='green')\n",
    "plt.plot(x, 1*x+2, color='blue')\n",
    "\n",
    "xData = numpy.array(data['apple'])\n",
    "yData = numpy.array(data['prices'])\n",
    "modelPredictions = numpy.array([1*x+2 for x in xData])\n",
    "\n",
    "# now add individual line for each point\n",
    "for i in range(len(xData)):\n",
    "    lineXdata = (xData[i], xData[i]) # same X\n",
    "    lineYdata = (yData[i], modelPredictions[i]) # different Y\n",
    "    plt.plot(lineXdata, lineYdata, color='black')\n",
    "\n",
    "plt.title(\"Apples and Prices\")\n",
    "plt.xlabel(\"Apples (lb)\")\n",
    "plt.ylabel(\"Price ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error\n",
    "error1 = abs(yData - modelPredictions)\n",
    "print(\"Residual errors are: \", numpy.sqrt(numpy.mean(error1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we find the error for the purple line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fitting line errors \n",
    "x = numpy.linspace(0, 12, 1000)\n",
    "plt.scatter(data['apple'], data['prices'], color='green')\n",
    "plt.plot(x, 1.5*x+3, color='purple')\n",
    "\n",
    "xData = numpy.array(data['apple'])\n",
    "yData = numpy.array(data['prices'])\n",
    "modelPredictions = numpy.array([1.5*x+3 for x in xData])\n",
    "\n",
    "# now add individual line for each point\n",
    "for i in range(len(xData)):\n",
    "    lineXdata = (xData[i], xData[i]) # same X\n",
    "    lineYdata = (yData[i], modelPredictions[i]) # different Y\n",
    "    plt.plot(lineXdata, lineYdata, color='black')\n",
    "\n",
    "plt.title(\"Apples and Prices\")\n",
    "plt.xlabel(\"Apples (lb)\")\n",
    "plt.ylabel(\"Price ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error\n",
    "error2 = abs(yData - modelPredictions)\n",
    "print(\"Residual errors are: \", numpy.sqrt(numpy.mean(error2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we find the error for the red line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fitting line errors \n",
    "x = numpy.linspace(0, 12, 1000)\n",
    "plt.scatter(data['apple'], data['prices'], color='green')\n",
    "plt.plot(x, 2*x+1, color='red')\n",
    "\n",
    "xData = numpy.array(data['apple'])\n",
    "yData = numpy.array(data['prices'])\n",
    "modelPredictions = numpy.array([2*x+1 for x in xData])\n",
    "\n",
    "# now add individual line for each point\n",
    "for i in range(len(xData)):\n",
    "    lineXdata = (xData[i], xData[i]) # same X\n",
    "    lineYdata = (yData[i], modelPredictions[i]) # different Y\n",
    "    plt.plot(lineXdata, lineYdata, color='black')\n",
    "\n",
    "plt.title(\"Apples and Prices\")\n",
    "plt.xlabel(\"Apples (lb)\")\n",
    "plt.ylabel(\"Price ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error\n",
    "error3 = abs(yData - modelPredictions)\n",
    "print(\"Residual errors are: \", numpy.sqrt(numpy.mean(error3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is how we determine that the red line is the \"best fitting\" line! It is the line with the least amount of residual error! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While here, we have determined that linear regression is the best choice for prediction, keep in mind that for more complex data sets, a curved line could also fit the data very well. Whenever visualization is possible, we should try to see what we can try to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for the World Happiness Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to take the World Happiness Dataset we examined last time and apply regression to it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load World Happiness Data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../assets/happinessDataset/2015.csv\")\n",
    "\n",
    "# View first five rows of the dataset\n",
    "df.head()\n",
    "\n",
    "#Scale and normalize data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = df[[\"Happiness Score\", 'Economy (GDP per Capita)', 'Family',\n",
    "       'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)',\n",
    "       'Generosity', 'Dystopia Residual']]\n",
    "# Separate training and testing datasets\n",
    "\n",
    "regression_data=df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "regression_test_data = df.drop(regression_data.index)\n",
    "\n",
    "#regression_data = regression_data.iloc[:150]\n",
    "#regression_test_data = regression_data.iloc[-8:]\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen how to do classification and clustering on this dataset now. We will now see if we can predict happiness score for a new country by learning a linear regression model using just one feature. We can use all the features to fit a linear model, but if the true data does not adhere to a linear model, then this will not give us good answers. For the sake of examples and demonstration, we will use a single feature first. We will see if we can use Economy as a feature for predicting the Happiness score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we visualize how the Happiness score changes with the economy. We can see how a linear fit would help us predict the happiness, given any value for the Economy variable for a new city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(regression_data['Economy (GDP per Capita)'],regression_data['Happiness Score'])\n",
    "plt.title('World Happiness Dataset')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.xlabel('Economy (GDP per capita) standardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Linear model from libary\n",
    "from sklearn import linear_model\n",
    "\n",
    "# create a linear regression model variable\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(numpy.array(regression_data['Economy (GDP per Capita)']).reshape(-1,1), numpy.array(regression_data['Happiness Score']))\n",
    "\n",
    "# plot data with the fitted line \n",
    "plt.scatter(regression_data['Economy (GDP per Capita)'],regression_data['Happiness Score'])\n",
    "plt.plot(regression_data['Economy (GDP per Capita)'], reg.coef_*regression_data['Economy (GDP per Capita)']+reg.intercept_, color='red')\n",
    "plt.title('World Happiness Dataset')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.xlabel('Economy (GDP per capita) standardized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slope and intercept of the best fitting line is given by: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Slope: \", reg.coef_)\n",
    "print(\"Intercept: \", reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you are given the economy data for a new country, you will be able to use the model to predict what the happiness score would be! Let's take an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg.predict(numpy.array(regression_test_data['Economy (GDP per Capita)']).reshape(-1,1))\n",
    "true_data = numpy.array(regression_test_data['Happiness Score'])\n",
    "\n",
    "# Measure mean square error between the true data and the predictions \n",
    "mse = abs(true_data - predictions)\n",
    "print(\"Residual errors are: \", numpy.sqrt(numpy.mean(mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity** Perform linear regression using the feature Health (Life Expectancy) to predict the happiness score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity Answers and Code** \n",
    "\n",
    "We can begin by visualizing the data to see if we think the data is roughly linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(regression_data['Health (Life Expectancy)'],regression_data['Happiness Score'])\n",
    "plt.title('World Happiness Dataset')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.xlabel('Health (Life Expectancy) standardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression model variable\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(numpy.array(regression_data['Health (Life Expectancy)']).reshape(-1,1), numpy.array(regression_data['Happiness Score']))\n",
    "\n",
    "# plot data with the fitted line \n",
    "plt.scatter(regression_data['Health (Life Expectancy)'],regression_data['Happiness Score'])\n",
    "plt.plot(regression_data['Health (Life Expectancy)'], reg.coef_*regression_data['Health (Life Expectancy)']+reg.intercept_, color='red')\n",
    "plt.title('World Happiness Dataset')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.xlabel('Health (Life Expectancy) standardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Slope: \", reg.coef_)\n",
    "print(\"Intercept: \", reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg.predict(numpy.array(regression_test_data['Health (Life Expectancy)']).reshape(-1,1))\n",
    "true_data = numpy.array(regression_test_data['Happiness Score'])\n",
    "\n",
    "# Measure mean square error between the true data and the predictions \n",
    "mse = abs(true_data - predictions)\n",
    "print(\"Residual errors are: \", numpy.sqrt(numpy.mean(mse)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
